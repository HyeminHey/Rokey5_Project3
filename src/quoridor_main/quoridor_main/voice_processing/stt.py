from openai import OpenAI
import sounddevice as sd
import scipy.io.wavfile as wav
import tempfile
import os

class STT:
    def __init__(self, openai_api_key):
        self.client = OpenAI(api_key=openai_api_key)
        self.duration = 5  # seconds
        self.samplerate = 16000  # WhisperëŠ” 16kHzë¥¼ ì„ í˜¸

    def speech2text(self):
        # ë…¹ìŒ ì„¤ì •
        print("ğŸ¤ ìŒì„± ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"   {self.duration}ì´ˆ ë™ì•ˆ ë§í•´ì£¼ì„¸ìš”...")
        
        audio = sd.rec(
            int(self.duration * self.samplerate), 
            samplerate=self.samplerate, 
            channels=1, 
            dtype='int16'
        )
        sd.wait()
        print("âœ… ë…¹ìŒ ì™„ë£Œ. Whisperì— ì „ì†¡ ì¤‘...")

        # ì„ì‹œ WAV íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
            temp_path = temp_wav.name
            wav.write(temp_path, self.samplerate, audio)

            # Whisper API í˜¸ì¶œ
            try:
                with open(temp_path, "rb") as f:
                    transcript = self.client.audio.transcriptions.create(
                        model="whisper-1", 
                        file=f,
                        language="ko"  # í•œêµ­ì–´ ëª…ì‹œ
                    )
                
                # âœ… ìˆ˜ì •: transcriptëŠ” ê°ì²´ì´ë¯€ë¡œ .textë¡œ ì ‘ê·¼
                result_text = transcript.text
                print(f"ğŸ“ STT ê²°ê³¼: {result_text}")
                
            except Exception as e:
                print(f"âŒ Whisper API ì˜¤ë¥˜: {e}")
                result_text = ""
            
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    os.unlink(temp_path)
                except:
                    pass
        
        return result_text
